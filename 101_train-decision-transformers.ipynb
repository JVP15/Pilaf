{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DktITQNXTopc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "import torch.utils.data\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from decision_transformer import DecisionTransformerConfig, DecisionTransformerModel\n",
    "\n",
    "import snowietxt_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFmTdHoHUD13"
   },
   "source": [
    "### Step 4: Defining a custom DataCollator for the transformers Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l1QzZHmPUM4p"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 5 #subsets of the episode we use for training\n",
    "    state_dim: int = 17  # size of state space\n",
    "    act_dim: int = 6  # size of action space\n",
    "    max_ep_len: int = 1000 # max episode length in the dataset\n",
    "    scale: float = 1.0  # normalization of rewards/returns\n",
    "    state_mean: np.array = None  # to store state means\n",
    "    state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
    "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
    "        self.dataset = dataset\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        traj_lens = []\n",
    "        for obs in dataset[\"observations\"]:\n",
    "            #states.extend(obs)\n",
    "            traj_lens.append(len(obs))\n",
    "        self.n_traj = len(traj_lens)\n",
    "        #states = np.vstack(states)\n",
    "        #self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "        \n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        \n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            #s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float().cuda()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float().cuda()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float().cuda()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float().cuda()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long().cuda()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float().cuda()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "        }\n",
    "\n",
    "class DummyCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # in this case, features should only ever be a single index because we've already created and collated the dataset ahead of time\n",
    "\n",
    "        return features[0]\n",
    "\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, states, actions, rewards, rtgs, timesteps, attention_mask):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "        self.attention_mask = attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"states\": self.states[idx],\n",
    "            \"actions\": self.actions[idx],\n",
    "            \"rewards\": self.rewards[idx],\n",
    "            \"returns_to_go\": self.rtgs[idx],\n",
    "            \"timesteps\": self.timesteps[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening games\\game0\n",
      "Opening games\\game1\n",
      "Opening games\\game2\n",
      "Opening games\\game3\n",
      "Opening games\\game4\n",
      "Opening games\\game5\n",
      "Opening games\\game6\n",
      "Opening games\\game7\n",
      "Opening games\\game8\n",
      "Opening games\\game9\n",
      "Opening games\\game10\n",
      "Opening games\\game11\n",
      "Opening games\\game12\n",
      "Opening games\\game13\n",
      "Opening games\\game14\n",
      "Opening games\\game15\n",
      "Opening games\\game16\n",
      "Opening games\\game17\n",
      "Opening games\\game18\n",
      "Opening games\\game19\n",
      "Opening games\\game20\n",
      "Opening games\\game21\n",
      "Opening games\\game22\n",
      "Opening games\\game23\n",
      "Opening games\\game24\n",
      "Opening games\\game25\n",
      "Opening games\\game26\n",
      "Opening games\\game27\n",
      "Opening games\\game28\n",
      "Opening games\\game29\n",
      "Opening games\\game30\n",
      "Opening games\\game31\n",
      "Opening games\\game32\n",
      "Opening games\\game33\n",
      "Opening games\\game34\n",
      "Opening games\\game35\n",
      "Opening games\\game36\n",
      "Opening games\\game37\n",
      "Opening games\\game38\n",
      "Opening games\\game39\n",
      "Opening games\\game40\n",
      "Opening games\\game41\n",
      "Opening games\\game42\n",
      "Opening games\\game43\n",
      "Opening games\\game44\n",
      "Opening games\\game45\n",
      "Opening games\\game46\n",
      "Opening games\\game47\n",
      "Opening games\\game48\n",
      "Opening games\\game49\n",
      "Opening games\\game50\n",
      "Opening games\\game51\n",
      "Opening games\\game52\n",
      "Opening games\\game53\n",
      "Opening games\\game54\n",
      "Opening games\\game55\n",
      "Opening games\\game56\n",
      "Opening games\\game57\n",
      "Opening games\\game58\n",
      "Opening games\\game59\n",
      "Number of games 5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5105/5105 [00:01<00:00, 2879.23it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = snowietxt_processor.create_dataset()\n",
    "dataset = datasets.Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to preprocess the dataset using the data collator we defined above (it also handles the batches\n",
    "# right now, just test to see how many batches we get using the collator and batch size of 64\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "collator = DecisionTransformerGymDataCollator(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states, actions, rewards, returns_to_go, timesteps, attention_mask = [], [], [], [], [], []\n",
    "\n",
    "num_batches = 0\n",
    "\n",
    "for batch in dataloader:\n",
    "    states.append(batch[\"states\"])\n",
    "    actions.append(batch[\"actions\"])\n",
    "    rewards.append(batch[\"rewards\"])\n",
    "    returns_to_go.append(batch[\"returns_to_go\"])\n",
    "    timesteps.append(batch[\"timesteps\"])\n",
    "    attention_mask.append(batch[\"attention_mask\"])\n",
    "\n",
    "    num_batches += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([5105, 5, 56])\n",
      "Actions shape: torch.Size([5105, 5, 8])\n",
      "States memory: 5.7176 MB\n",
      "Actions memory: 0.8168 MB\n"
     ]
    }
   ],
   "source": [
    "# calculate how much memory the states take up\n",
    "states_view = torch.cat(states, dim=0)\n",
    "actions_view = torch.cat(actions, dim=0)\n",
    "\n",
    "print(f\"States shape: {states_view.shape}\")\n",
    "print(f\"Actions shape: {actions_view.shape}\")\n",
    "\n",
    "# calculate how much memory the states take up\n",
    "print(f\"States memory: {states_view.element_size() * states_view.nelement() / 1e6} MB\")\n",
    "print(f\"Actions memory: {actions_view.element_size() * actions_view.nelement() / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 6.,  ..., 3., 3., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 3., 0.],\n",
      "         [0., 1., 5.,  ..., 3., 3., 0.],\n",
      "         [1., 0., 6.,  ..., 3., 3., 1.],\n",
      "         [0., 1., 6.,  ..., 3., 3., 0.]],\n",
      "\n",
      "        [[1., 0., 3.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 6.,  ..., 4., 1., 0.],\n",
      "         [1., 0., 4.,  ..., 4., 1., 0.],\n",
      "         [0., 1., 3.,  ..., 3., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 2., 0.]],\n",
      "\n",
      "        [[0., 1., 5.,  ..., 2., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 2., 2., 0.],\n",
      "         [0., 1., 3.,  ..., 2., 2., 0.],\n",
      "         [1., 0., 2.,  ..., 2., 2., 0.],\n",
      "         [0., 1., 6.,  ..., 3., 3., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 4.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 5.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 5.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 4.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 4.,  ..., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 2.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 5.,  ..., 1., 0., 0.],\n",
      "         [1., 0., 5.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 6.,  ..., 2., 0., 0.],\n",
      "         [1., 0., 4.,  ..., 2., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 4.,  ..., 3., 2., 0.],\n",
      "         [0., 1., 5.,  ..., 3., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 2., 1.],\n",
      "         [0., 1., 6.,  ..., 3., 2., 1.],\n",
      "         [1., 0., 6.,  ..., 3., 2., 1.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, create a new dataset based on the collated data\n",
    "# dataset = Dataset.from_dict(\n",
    "#     {\n",
    "#         \"states\": states,\n",
    "#         \"actions\": actions,\n",
    "#         \"rewards\": rewards,\n",
    "#         \"returns_to_go\": returns_to_go,\n",
    "#         \"timesteps\": timesteps,\n",
    "#         \"attention_mask\": attention_mask,\n",
    "#     }\n",
    "# )\n",
    "\n",
    "dataset = DummyDataset(states, actions, rewards, returns_to_go, timesteps, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 6.,  ..., 3., 3., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 3., 0.],\n",
      "         [0., 1., 5.,  ..., 3., 3., 0.],\n",
      "         [1., 0., 6.,  ..., 3., 3., 1.],\n",
      "         [0., 1., 6.,  ..., 3., 3., 0.]],\n",
      "\n",
      "        [[1., 0., 3.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 6.,  ..., 4., 1., 0.],\n",
      "         [1., 0., 4.,  ..., 4., 1., 0.],\n",
      "         [0., 1., 3.,  ..., 3., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 2., 0.]],\n",
      "\n",
      "        [[0., 1., 5.,  ..., 2., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 2., 2., 0.],\n",
      "         [0., 1., 3.,  ..., 2., 2., 0.],\n",
      "         [1., 0., 2.,  ..., 2., 2., 0.],\n",
      "         [0., 1., 6.,  ..., 3., 3., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 1., 4.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 5.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 5.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 4.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 4.,  ..., 1., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 2.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 5.,  ..., 1., 0., 0.],\n",
      "         [1., 0., 5.,  ..., 1., 0., 0.],\n",
      "         [0., 1., 6.,  ..., 2., 0., 0.],\n",
      "         [1., 0., 4.,  ..., 2., 0., 0.]],\n",
      "\n",
      "        [[1., 0., 4.,  ..., 3., 2., 0.],\n",
      "         [0., 1., 5.,  ..., 3., 2., 0.],\n",
      "         [1., 0., 4.,  ..., 3., 2., 1.],\n",
      "         [0., 1., 6.,  ..., 3., 2., 1.],\n",
      "         [1., 0., 6.,  ..., 3., 2., 1.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['states'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmTRGPKYUVFG"
   },
   "source": [
    "### Step 5: Extending the Decision Transformer Model to include a loss function\n",
    "\n",
    "In order to train the model with the ðŸ¤— trainer class, we first need to ensure the dictionary it returns contains a loss, in this case L-2 norm of the models action predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "bwZp7hhFUh5u"
   },
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "        # add the DT loss\n",
    "        action_preds = output[1]\n",
    "        action_targets = kwargs[\"actions\"]\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "\n",
    "        act_dim = action_preds.shape[2]\n",
    "        action_preds = action_preds.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0]\n",
    "        \n",
    "        loss = torch.mean((action_preds - action_targets) ** 2)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "zIJCY3b3pQAh"
   },
   "outputs": [],
   "source": [
    "dummy_collator = DummyCollator()\n",
    "\n",
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim, n_positions=512, action_tanh=False)\n",
    "model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJ2mr_cU4eE"
   },
   "source": [
    "### Step 6: Defining the training hyperparameters and training the model\n",
    "Here, we define the training hyperparameters and our Trainer class that we'll use to train our Decision Transformer model.\n",
    "\n",
    "This step takes about an hour, so you may leave it running. Note the authors train for at least 3 hours, so the results presented here are not as performant as the models hosted on the ðŸ¤— hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nNzzKWuuU9I4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using cuda_amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 120\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9600\n",
      "  Number of trainable parameters = 1202369\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9600' max='9600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9600/9600 01:47, Epoch 120/120]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>96.284500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>64.504100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>39.112700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>26.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>19.793300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>16.357000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>14.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>13.198700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>12.346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>11.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>11.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>10.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>10.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>10.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>9.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>9.523500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>9.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>9.229700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>9.169400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-500\n",
      "Configuration saved in output/checkpoint-500\\config.json\n",
      "Model weights saved in output/checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000\\config.json\n",
      "Model weights saved in output/checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1500\n",
      "Configuration saved in output/checkpoint-1500\\config.json\n",
      "Model weights saved in output/checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-2000\n",
      "Configuration saved in output/checkpoint-2000\\config.json\n",
      "Model weights saved in output/checkpoint-2000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-2500\n",
      "Configuration saved in output/checkpoint-2500\\config.json\n",
      "Model weights saved in output/checkpoint-2500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-3000\n",
      "Configuration saved in output/checkpoint-3000\\config.json\n",
      "Model weights saved in output/checkpoint-3000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-3500\n",
      "Configuration saved in output/checkpoint-3500\\config.json\n",
      "Model weights saved in output/checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-4000\n",
      "Configuration saved in output/checkpoint-4000\\config.json\n",
      "Model weights saved in output/checkpoint-4000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-4500\n",
      "Configuration saved in output/checkpoint-4500\\config.json\n",
      "Model weights saved in output/checkpoint-4500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-5000\n",
      "Configuration saved in output/checkpoint-5000\\config.json\n",
      "Model weights saved in output/checkpoint-5000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-5500\n",
      "Configuration saved in output/checkpoint-5500\\config.json\n",
      "Model weights saved in output/checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-6000\n",
      "Configuration saved in output/checkpoint-6000\\config.json\n",
      "Model weights saved in output/checkpoint-6000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-6500\n",
      "Configuration saved in output/checkpoint-6500\\config.json\n",
      "Model weights saved in output/checkpoint-6500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-7000\n",
      "Configuration saved in output/checkpoint-7000\\config.json\n",
      "Model weights saved in output/checkpoint-7000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-7500\n",
      "Configuration saved in output/checkpoint-7500\\config.json\n",
      "Model weights saved in output/checkpoint-7500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-8000\n",
      "Configuration saved in output/checkpoint-8000\\config.json\n",
      "Model weights saved in output/checkpoint-8000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-8500\n",
      "Configuration saved in output/checkpoint-8500\\config.json\n",
      "Model weights saved in output/checkpoint-8500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-9000\n",
      "Configuration saved in output/checkpoint-9000\\config.json\n",
      "Model weights saved in output/checkpoint-9000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-9500\n",
      "Configuration saved in output/checkpoint-9500\\config.json\n",
      "Model weights saved in output/checkpoint-9500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9600, training_loss=21.104205169677734, metrics={'train_runtime': 107.983, 'train_samples_per_second': 88.903, 'train_steps_per_second': 88.903, 'total_flos': 630279979056000.0, 'train_loss': 21.104205169677734, 'epoch': 120.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=120,\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    "    tf32=True,\n",
    "    fp16=True,\n",
    "    #dataloader_num_workers=8\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=dummy_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 12\u001B[0m     output \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39moriginal_forward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mbatch)\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(output[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maction_preds\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mround())\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mactions\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[1;32mIn[11], line 21\u001B[0m, in \u001B[0;36mTrainableDT.original_forward\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21moriginal_forward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mforward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\Documents\\Python\\Pilaf\\decision_transformer\\modeling_decision_transformer.py:897\u001B[0m, in \u001B[0;36mDecisionTransformerModel.forward\u001B[1;34m(self, states, actions, rewards, returns_to_go, timesteps, attention_mask, output_hidden_states, output_attentions, return_dict)\u001B[0m\n\u001B[0;32m    894\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mones((batch_size, seq_length), dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mlong)\n\u001B[0;32m    896\u001B[0m \u001B[38;5;66;03m# embed each modality with a different head\u001B[39;00m\n\u001B[1;32m--> 897\u001B[0m state_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43membed_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    898\u001B[0m action_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_action(actions)\n\u001B[0;32m    899\u001B[0m returns_embeddings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_return(returns_to_go)\n",
      "File \u001B[1;32m~\\.conda\\envs\\Perceiver\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\.conda\\envs\\Perceiver\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a dataloader for evaluation\n",
    "eval_dataloader = DataLoader(dataset, batch_size=1, collate_fn=collator)\n",
    "\n",
    "# get one batch from the dataloader and run it through the model\n",
    "batch = next(iter(eval_dataloader))\n",
    "\n",
    "model.eval()\n",
    "model.cpu()\n",
    "with torch.no_grad():\n",
    "    output = model.original_forward(**batch)\n",
    "\n",
    "print(output['action_preds'].round())\n",
    "print(batch['actions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
