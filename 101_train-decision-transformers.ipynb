{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DktITQNXTopc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "from preprocessed_dataset import DecisionTransformerPreprocessedDataset, UnwrapCollator\n",
    "import torch.utils.data\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from decision_transformer import DecisionTransformerConfig, DecisionTransformerModel\n",
    "\n",
    "import snowietxt_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MAX_LEN = 10\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 120"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFmTdHoHUD13"
   },
   "source": [
    "### Step 4: Defining a custom DataCollator for the transformers Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of games 5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5105/5105 [00:01<00:00, 2677.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = snowietxt_processor.create_dataset()\n",
    "dataset = datasets.Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [04:20<00:00,  1.84batch/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = DecisionTransformerPreprocessedDataset(dataset, max_len=MAX_LEN, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmTRGPKYUVFG"
   },
   "source": [
    "### Step 5: Extending the Decision Transformer Model to include a loss function\n",
    "\n",
    "In order to train the model with the ðŸ¤— trainer class, we first need to ensure the dictionary it returns contains a loss, in this case L-2 norm of the models action predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zIJCY3b3pQAh"
   },
   "outputs": [],
   "source": [
    "config = DecisionTransformerConfig(state_dim=dataset.state_dim, act_dim=dataset.act_dim, max_length=MAX_LEN)\n",
    "model = DecisionTransformerModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "20"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.max_length"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJ2mr_cU4eE"
   },
   "source": [
    "### Step 6: Defining the training hyperparameters and training the model\n",
    "Here, we define the training hyperparameters and our Trainer class that we'll use to train our Decision Transformer model.\n",
    "\n",
    "This step takes about an hour, so you may leave it running. Note the authors train for at least 3 hours, so the results presented here are not as performant as the models hosted on the ðŸ¤— hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "nNzzKWuuU9I4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using cuda_amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 480\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 9600\n",
      "  Number of trainable parameters = 1349795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9600' max='9600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9600/9600 02:05, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.601700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.339300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.093200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.961900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.927300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.899500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.873800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.848900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.820700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.797300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.776900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.755600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.708900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.698700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.689400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.685400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-500\n",
      "Configuration saved in output/checkpoint-500\\config.json\n",
      "Model weights saved in output/checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000\\config.json\n",
      "Model weights saved in output/checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1500\n",
      "Configuration saved in output/checkpoint-1500\\config.json\n",
      "Model weights saved in output/checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-2000\n",
      "Configuration saved in output/checkpoint-2000\\config.json\n",
      "Model weights saved in output/checkpoint-2000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-2500\n",
      "Configuration saved in output/checkpoint-2500\\config.json\n",
      "Model weights saved in output/checkpoint-2500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-3000\n",
      "Configuration saved in output/checkpoint-3000\\config.json\n",
      "Model weights saved in output/checkpoint-3000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-3500\n",
      "Configuration saved in output/checkpoint-3500\\config.json\n",
      "Model weights saved in output/checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-4000\n",
      "Configuration saved in output/checkpoint-4000\\config.json\n",
      "Model weights saved in output/checkpoint-4000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-4500\n",
      "Configuration saved in output/checkpoint-4500\\config.json\n",
      "Model weights saved in output/checkpoint-4500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-5000\n",
      "Configuration saved in output/checkpoint-5000\\config.json\n",
      "Model weights saved in output/checkpoint-5000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-5500\n",
      "Configuration saved in output/checkpoint-5500\\config.json\n",
      "Model weights saved in output/checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-6000\n",
      "Configuration saved in output/checkpoint-6000\\config.json\n",
      "Model weights saved in output/checkpoint-6000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-6500\n",
      "Configuration saved in output/checkpoint-6500\\config.json\n",
      "Model weights saved in output/checkpoint-6500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-7000\n",
      "Configuration saved in output/checkpoint-7000\\config.json\n",
      "Model weights saved in output/checkpoint-7000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-7500\n",
      "Configuration saved in output/checkpoint-7500\\config.json\n",
      "Model weights saved in output/checkpoint-7500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-8000\n",
      "Configuration saved in output/checkpoint-8000\\config.json\n",
      "Model weights saved in output/checkpoint-8000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-8500\n",
      "Configuration saved in output/checkpoint-8500\\config.json\n",
      "Model weights saved in output/checkpoint-8500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-9000\n",
      "Configuration saved in output/checkpoint-9000\\config.json\n",
      "Model weights saved in output/checkpoint-9000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-9500\n",
      "Configuration saved in output/checkpoint-9500\\config.json\n",
      "Model weights saved in output/checkpoint-9500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9600, training_loss=0.9416190870602925, metrics={'train_runtime': 127.9303, 'train_samples_per_second': 75.041, 'train_steps_per_second': 75.041, 'total_flos': 5359189099320000.0, 'train_loss': 0.9416190870602925, 'epoch': 20.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    "    tf32=True,\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=UnwrapCollator(),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[25, 23, 13, 10,  6,  5,  6,  4],\n",
      "        [17, 21, 19, 22,  0,  0,  0,  0],\n",
      "        [25, 23, 24, 22,  0,  0,  0,  0],\n",
      "        [12, 16, 15, 18,  0,  0,  0,  0],\n",
      "        [18, 16, 13, 11,  0,  0,  0,  0],\n",
      "        [17, 20, 19, 23,  0,  0,  0,  0],\n",
      "        [25, 20,  8,  5,  0,  0,  0,  0],\n",
      "        [12, 14, 12, 15,  0,  0,  0,  0],\n",
      "        [25, 23, 13,  5,  0,  0,  0,  0],\n",
      "        [ 0,  2, 19, 23,  0,  0,  0,  0]], device='cuda:0')\n",
      "tensor([[23., 21., 13., 11.,  6.,  4.,  6.,  4.],\n",
      "        [17., 21., 19., 21.,  0.,  0.,  0.,  0.],\n",
      "        [25., 22., 24., 20.,  0.,  0.,  0.,  0.],\n",
      "        [12., 16., 16., 18.,  0.,  0.,  0.,  0.],\n",
      "        [20., 14., 14., 11.,  0.,  0.,  0.,  0.],\n",
      "        [18., 19., 19., 23.,  0.,  0.,  0.,  0.],\n",
      "        [22., 16.,  8.,  4.,  0.,  0.,  0.,  0.],\n",
      "        [12., 14., 12., 16.,  0.,  0.,  0.,  0.],\n",
      "        [25., 23., 11.,  5.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  5., 19., 23.,  0.,  0.,  0.,  0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a dataloader for evaluation\n",
    "eval_dataloader = DataLoader(dataset, batch_size=1, collate_fn=UnwrapCollator())\n",
    "\n",
    "# get one batch from the dataloader and run it through the model\n",
    "batch = next(iter(eval_dataloader))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.forward(**batch)\n",
    "\n",
    "print(output['action_preds'][1].argmax(dim=-1))\n",
    "print(batch['actions'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
