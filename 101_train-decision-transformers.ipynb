{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DktITQNXTopc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "import datasets\n",
    "import torch.utils.data\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from decision_transformer import DecisionTransformerConfig, DecisionTransformerModel\n",
    "\n",
    "import snowietxt_processor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "torch.backends.cuda.matmul.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFmTdHoHUD13"
   },
   "source": [
    "### Step 4: Defining a custom DataCollator for the transformers Trainer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "l1QzZHmPUM4p"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DecisionTransformerGymDataCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "    max_len: int = 10 #subsets of the episode we use for training\n",
    "    state_dim: int = 17  # size of state space\n",
    "    act_dim: int = 6  # size of action space\n",
    "    max_ep_len: int = 1000 # max episode length in the dataset\n",
    "    scale: float = 1.0  # normalization of rewards/returns\n",
    "    state_mean: np.array = None  # to store state means\n",
    "    state_std: np.array = None  # to store state stds\n",
    "    p_sample: np.array = None  # a distribution to take account trajectory lengths\n",
    "    n_traj: int = 0 # to store the number of trajectories in the dataset\n",
    "\n",
    "    def __init__(self, dataset) -> None:\n",
    "        self.act_dim = len(dataset[0][\"actions\"][0])\n",
    "        self.state_dim = len(dataset[0][\"observations\"][0])\n",
    "        self.dataset = dataset\n",
    "        # calculate dataset stats for normalization of states\n",
    "        states = []\n",
    "        traj_lens = []\n",
    "        for obs in dataset[\"observations\"]:\n",
    "            #states.extend(obs)\n",
    "            traj_lens.append(len(obs))\n",
    "        self.n_traj = len(traj_lens)\n",
    "        #states = np.vstack(states)\n",
    "        #self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "        \n",
    "        traj_lens = np.array(traj_lens)\n",
    "        self.p_sample = traj_lens / sum(traj_lens)\n",
    "\n",
    "    def _discount_cumsum(self, x, gamma):\n",
    "        discount_cumsum = np.zeros_like(x)\n",
    "        discount_cumsum[-1] = x[-1]\n",
    "        for t in reversed(range(x.shape[0] - 1)):\n",
    "            discount_cumsum[t] = x[t] + gamma * discount_cumsum[t + 1]\n",
    "        return discount_cumsum\n",
    "\n",
    "    def __call__(self, features):\n",
    "        batch_size = len(features)\n",
    "        # this is a bit of a hack to be able to sample of a non-uniform distribution\n",
    "        batch_inds = np.random.choice(\n",
    "            np.arange(self.n_traj),\n",
    "            size=batch_size,\n",
    "            replace=True,\n",
    "            p=self.p_sample,  # reweights so we sample according to timesteps\n",
    "        )\n",
    "        # a batch of dataset features\n",
    "        s, a, r, d, rtg, timesteps, mask = [], [], [], [], [], [], []\n",
    "        \n",
    "        for ind in batch_inds:\n",
    "            # for feature in features:\n",
    "            feature = self.dataset[int(ind)]\n",
    "            si = random.randint(0, len(feature[\"rewards\"]) - 1)\n",
    "\n",
    "            # get sequences from dataset\n",
    "            s.append(np.array(feature[\"observations\"][si : si + self.max_len]).reshape(1, -1, self.state_dim))\n",
    "            a.append(np.array(feature[\"actions\"][si : si + self.max_len]).reshape(1, -1, self.act_dim))\n",
    "            r.append(np.array(feature[\"rewards\"][si : si + self.max_len]).reshape(1, -1, 1))\n",
    "\n",
    "            d.append(np.array(feature[\"dones\"][si : si + self.max_len]).reshape(1, -1))\n",
    "            timesteps.append(np.arange(si, si + s[-1].shape[1]).reshape(1, -1))\n",
    "            timesteps[-1][timesteps[-1] >= self.max_ep_len] = self.max_ep_len - 1  # padding cutoff\n",
    "            rtg.append(\n",
    "                self._discount_cumsum(np.array(feature[\"rewards\"][si:]), gamma=1.0)[\n",
    "                    : s[-1].shape[1]   # TODO check the +1 removed here\n",
    "                ].reshape(1, -1, 1)\n",
    "            )\n",
    "            if rtg[-1].shape[1] < s[-1].shape[1]:\n",
    "                print(\"if true\")\n",
    "                rtg[-1] = np.concatenate([rtg[-1], np.zeros((1, 1, 1))], axis=1)\n",
    "\n",
    "            # padding and state + reward normalization\n",
    "            tlen = s[-1].shape[1]\n",
    "            s[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, self.state_dim)), s[-1]], axis=1)\n",
    "            #s[-1] = (s[-1] - self.state_mean) / self.state_std\n",
    "            a[-1] = np.concatenate(\n",
    "                [np.ones((1, self.max_len - tlen, self.act_dim)) * -10.0, a[-1]],\n",
    "                axis=1,\n",
    "            )\n",
    "            r[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), r[-1]], axis=1)\n",
    "            d[-1] = np.concatenate([np.ones((1, self.max_len - tlen)) * 2, d[-1]], axis=1)\n",
    "            rtg[-1] = np.concatenate([np.zeros((1, self.max_len - tlen, 1)), rtg[-1]], axis=1) / self.scale\n",
    "            timesteps[-1] = np.concatenate([np.zeros((1, self.max_len - tlen)), timesteps[-1]], axis=1)\n",
    "            mask.append(np.concatenate([np.zeros((1, self.max_len - tlen)), np.ones((1, tlen))], axis=1))\n",
    "\n",
    "        s = torch.from_numpy(np.concatenate(s, axis=0)).float().cuda()\n",
    "        a = torch.from_numpy(np.concatenate(a, axis=0)).float().cuda()\n",
    "        r = torch.from_numpy(np.concatenate(r, axis=0)).float().cuda()\n",
    "        d = torch.from_numpy(np.concatenate(d, axis=0))\n",
    "        rtg = torch.from_numpy(np.concatenate(rtg, axis=0)).float().cuda()\n",
    "        timesteps = torch.from_numpy(np.concatenate(timesteps, axis=0)).long().cuda()\n",
    "        mask = torch.from_numpy(np.concatenate(mask, axis=0)).float().cuda()\n",
    "\n",
    "        return {\n",
    "            \"states\": s,\n",
    "            \"actions\": a,\n",
    "            \"rewards\": r,\n",
    "            \"returns_to_go\": rtg,\n",
    "            \"timesteps\": timesteps,\n",
    "            \"attention_mask\": mask,\n",
    "        }\n",
    "\n",
    "class DummyCollator:\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # in this case, features should only ever be a single index because we've already created and collated the dataset ahead of time\n",
    "\n",
    "        return features[0]\n",
    "\n",
    "class DummyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, states, actions, rewards, rtgs, timesteps, attention_mask):\n",
    "        self.states = states\n",
    "        self.actions = actions\n",
    "        self.rewards = rewards\n",
    "        self.rtgs = rtgs\n",
    "        self.timesteps = timesteps\n",
    "        self.attention_mask = attention_mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.states)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"states\": self.states[idx],\n",
    "            \"actions\": self.actions[idx],\n",
    "            \"rewards\": self.rewards[idx],\n",
    "            \"returns_to_go\": self.rtgs[idx],\n",
    "            \"timesteps\": self.timesteps[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening games\\game0\n",
      "Opening games\\game1\n",
      "Opening games\\game2\n",
      "Opening games\\game3\n",
      "Opening games\\game4\n",
      "Opening games\\game5\n",
      "Opening games\\game6\n",
      "Opening games\\game7\n",
      "Opening games\\game8\n",
      "Opening games\\game9\n",
      "Opening games\\game10\n",
      "Opening games\\game11\n",
      "Opening games\\game12\n",
      "Opening games\\game13\n",
      "Opening games\\game14\n",
      "Opening games\\game15\n",
      "Opening games\\game16\n",
      "Opening games\\game17\n",
      "Opening games\\game18\n",
      "Opening games\\game19\n",
      "Opening games\\game20\n",
      "Opening games\\game21\n",
      "Opening games\\game22\n",
      "Opening games\\game23\n",
      "Opening games\\game24\n",
      "Opening games\\game25\n",
      "Opening games\\game26\n",
      "Opening games\\game27\n",
      "Opening games\\game28\n",
      "Opening games\\game29\n",
      "Opening games\\game30\n",
      "Opening games\\game31\n",
      "Opening games\\game32\n",
      "Opening games\\game33\n",
      "Opening games\\game34\n",
      "Opening games\\game35\n",
      "Opening games\\game36\n",
      "Opening games\\game37\n",
      "Opening games\\game38\n",
      "Opening games\\game39\n",
      "Opening games\\game40\n",
      "Opening games\\game41\n",
      "Opening games\\game42\n",
      "Opening games\\game43\n",
      "Opening games\\game44\n",
      "Opening games\\game45\n",
      "Opening games\\game46\n",
      "Opening games\\game47\n",
      "Opening games\\game48\n",
      "Opening games\\game49\n",
      "Opening games\\game50\n",
      "Opening games\\game51\n",
      "Opening games\\game52\n",
      "Opening games\\game53\n",
      "Opening games\\game54\n",
      "Opening games\\game55\n",
      "Opening games\\game56\n",
      "Opening games\\game57\n",
      "Opening games\\game58\n",
      "Opening games\\game59\n",
      "Number of games 5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5105/5105 [00:01<00:00, 2969.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = snowietxt_processor.create_dataset()\n",
    "dataset = datasets.Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to preprocess the dataset using the data collator we defined above (it also handles the batches\n",
    "# right now, just test to see how many batches we get using the collator and batch size of 64\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "collator = DecisionTransformerGymDataCollator(dataset)\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [00:32<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "states, actions, rewards, returns_to_go, timesteps, attention_mask = [], [], [], [], [], []\n",
    "\n",
    "num_batches = 0\n",
    "\n",
    "for i in range(10 // DecisionTransformerGymDataCollator.max_len): # TODO: figure out the average length of an episode\n",
    "    for batch in tqdm(dataloader, total=len(dataloader)):\n",
    "        states.append(batch[\"states\"])\n",
    "        actions.append(batch[\"actions\"])\n",
    "        rewards.append(batch[\"rewards\"])\n",
    "        returns_to_go.append(batch[\"returns_to_go\"])\n",
    "        timesteps.append(batch[\"timesteps\"])\n",
    "        attention_mask.append(batch[\"attention_mask\"])\n",
    "\n",
    "        num_batches += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "States shape: torch.Size([5105, 10, 210])\n",
      "Actions shape: torch.Size([5105, 10, 8])\n",
      "States memory: 42.882 MB\n",
      "Actions memory: 1.6336 MB\n"
     ]
    }
   ],
   "source": [
    "# calculate how much memory the states take up\n",
    "states_view = torch.cat(states, dim=0)\n",
    "actions_view = torch.cat(actions, dim=0)\n",
    "\n",
    "print(f\"States shape: {states_view.shape}\")\n",
    "print(f\"Actions shape: {actions_view.shape}\")\n",
    "\n",
    "# calculate how much memory the states take up\n",
    "print(f\"States memory: {states_view.element_size() * states_view.nelement() / 1e6} MB\")\n",
    "print(f\"Actions memory: {actions_view.element_size() * actions_view.nelement() / 1e6} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 0., 1.],\n",
      "         ...,\n",
      "         [1., 1., 1.,  ..., 0., 1., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "        [[1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         ...,\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 0.,  ..., 1., 0., 0.]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = DummyDataset(states, actions, rewards, returns_to_go, timesteps, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10, 210])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['states'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0]['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmTRGPKYUVFG"
   },
   "source": [
    "### Step 5: Extending the Decision Transformer Model to include a loss function\n",
    "\n",
    "In order to train the model with the 🤗 trainer class, we first need to ensure the dictionary it returns contains a loss, in this case L-2 norm of the models action predictions and the targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bwZp7hhFUh5u"
   },
   "outputs": [],
   "source": [
    "class TrainableDT(DecisionTransformerModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        output = super().forward(**kwargs)\n",
    "\n",
    "        action_preds = output['action_preds'] # shape = [batch_size, seq_len, act_dim, action_vocab_size]\n",
    "        action_targets = kwargs[\"actions\"] # shape = [batch_size, seq_len, act_dim]\n",
    "        attention_mask = kwargs[\"attention_mask\"] # shape = [batch_size, seq_len]\n",
    "\n",
    "        act_dim, action_vocab_size = action_preds.shape[2], action_preds.shape[3]\n",
    "\n",
    "        # we need to resize the tensor to [batch_size * seq_len, act_dim, action_vocab_size]\n",
    "        action_preds = action_preds.reshape(-1, act_dim, action_vocab_size)[attention_mask.reshape(-1) > 0]\n",
    "        # we have to reshape the preds to [batch_size * seq_len, action_vocab_size, act_dim] b/c CrossEntropyLoss expects (N, C, d1...) where C is the number of classes and d1 is an extra dimension\n",
    "        action_preds = action_preds.permute(0, 2, 1)\n",
    "        action_targets = action_targets.reshape(-1, act_dim)[attention_mask.reshape(-1) > 0].long() # the input expects our actions to be floats, but CrossEntropy expects the targets to be Longs\n",
    "        \n",
    "        loss = self.loss_fn(action_preds, action_targets)\n",
    "\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def original_forward(self, **kwargs):\n",
    "        return super().forward(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zIJCY3b3pQAh"
   },
   "outputs": [],
   "source": [
    "dummy_collator = DummyCollator()\n",
    "\n",
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim, action_tanh=False)\n",
    "model = TrainableDT(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJJ2mr_cU4eE"
   },
   "source": [
    "### Step 6: Defining the training hyperparameters and training the model\n",
    "Here, we define the training hyperparameters and our Trainer class that we'll use to train our Decision Transformer model.\n",
    "\n",
    "This step takes about an hour, so you may leave it running. Note the authors train for at least 3 hours, so the results presented here are not as performant as the models hosted on the 🤗 hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "nNzzKWuuU9I4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "Using cuda_amp half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 80\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1600\n",
      "  Number of trainable parameters = 1349795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1600' max='1600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1600/1600 00:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.154500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.054500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to output/checkpoint-500\n",
      "Configuration saved in output/checkpoint-500\\config.json\n",
      "Model weights saved in output/checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1000\n",
      "Configuration saved in output/checkpoint-1000\\config.json\n",
      "Model weights saved in output/checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to output/checkpoint-1500\n",
      "Configuration saved in output/checkpoint-1500\\config.json\n",
      "Model weights saved in output/checkpoint-1500\\pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1600, training_loss=1.3510638427734376, metrics={'train_runtime': 20.7308, 'train_samples_per_second': 77.18, 'train_steps_per_second': 77.18, 'total_flos': 893198183220000.0, 'train_loss': 1.3510638427734376, 'epoch': 20.0})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    remove_unused_columns=False,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=1,\n",
    "    learning_rate=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    warmup_ratio=0.1,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=0.25,\n",
    "    tf32=True,\n",
    "    fp16=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    data_collator=dummy_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  1, 12, 15, 12, 18, 19, 20],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 15, 12, 18,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [12, 15, 12, 18,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  5, 12, 17,  0,  0,  0,  0],\n",
      "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
      "        [ 0,  5, 12, 18,  0,  0,  0,  0],\n",
      "        [25, 24,  0,  0,  0,  0,  0,  0]], device='cuda:0')\n",
      "tensor([[ 5., 11., 11., 17., 17., 23., 17., 23.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [12., 14., 14., 15.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [12., 14., 14., 19.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 5.,  7., 12., 18.,  0.,  0.,  0.,  0.],\n",
      "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
      "        [ 7.,  9., 15., 21.,  0.,  0.,  0.,  0.],\n",
      "        [25., 24.,  0.,  0.,  0.,  0.,  0.,  0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# create a dataloader for evaluation\n",
    "eval_dataloader = DataLoader(dataset, batch_size=1, collate_fn=dummy_collator)\n",
    "\n",
    "# get one batch from the dataloader and run it through the model\n",
    "batch = next(iter(eval_dataloader))\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model.original_forward(**batch)\n",
    "\n",
    "print(output['action_preds'][0].argmax(dim=-1))\n",
    "print(batch['actions'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
